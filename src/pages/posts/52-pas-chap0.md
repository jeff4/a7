---
layout: ../../layouts/MdPostDescLayout.astro
title: 'Introduction'
LastUpdatedDate: 2024-01-10
CreatedDate: 2023-12-25
description: 'Matteo Pasquinelli'
author: 'Jeff'
tags: []


---
## AI as Division of Labour
### Quotes
1. Karl Marx *Capital* (1867): "The special skill of each individual machine-operator, who has now been deprived of all significance, vanishes as an infinitesimal quantity in the face of the science, the gigantic natural forces, and the mass of the social labour embodied in the system of machinery, which, together with these three forces, constitutes the power of the 'master'."

1. Gramsci (1932): "All human beings are intellectuals ... although one can speak of intellectuals, one cannot speak of non-intellectuals, because non-intellectuals do not exist ... There is no human activity from which every form of intellectual participation can be excluded: *Homo faber* cannot be separated from *homo sapiens*."


### 01 JH Break
1. In the twentieth century, few would have ever defined a truck driver as a 'cognitive worker', an intellectual. 
1. In the early twenty-first, however, the application of artificial intelligence (AI) in self-driving vehicles, among other artefacts, has changed the perception of manual skills such as driving, revealing how the most valuable component of work in general has never been just manual, but has always been cognitive and cooperative as well. 
1. Thanks to AI research -- we must acknowledge it -- truck drivers have reached the pantheon of intelligentsia. 
1. It is a paradox -- a bitter political revelation -- that the most zealous development of automation has shown how much 'intelligence' is expressed by activities and jobs that are usually deemed manual and unskilled, an aspect that has often been neglected by labour organisation as much as critical theory. 
1. In fact, in the current digital age, only a few sociologists, such as Richard Sennett, have taken the trouble to emphasise that 'making is thinking', a dimension that the historians of science such as Lissa Roberts and Simon Schaffer have captured in the elegant image of the 'mindful hand' -- a hand that, in the workshop of the Renaissance as much as in those of the industrial age, has not only expressed muscular strength but also inspired design, inventions, and scientific breakthroughs. If there is a denial of the intelligence of manual labour and social activities today, that seems to be a symptom also of the overgrowth of the digital sphere and the dematerialisation of human activities, which have contributed to the aura of mystery that has been eventually constructed around AI.  

### 02 JH Break

1. What is AI? A dominant view describes it as the quest 'to solve intelligence' -- a solution supposedly to be found in the secret logic of the mind or in the deep physiology of the brain, such as in its complex neural networks. 
1. In this book I argue, to the contrary, that the inner code of AI is constituted not by the imitation of biological intelligence but by the *intelligence of labour and social relations*. 
1. Today, it should be evident that AI is a project to capture the knowledge expressed through individual and collective behaviours and encode it into algorithmic models to automate the most diverse tasks: from image recognition and object manipulation to language translation and decision-making. 
1. As in a typical effect of ideology, the 'solution' to the enigma of AI is in front of our eyes, but nobody can see it -- nor does anybody want to.
1. Let us return to the contested project of the self-driving car. What kind of work does a driver perform? 
1. And to what extent can AI automate such an activity? 
1. With a considerable degree of approximation and hazard, a self-driving vehicle is designed to imitate all the micro-decisions that a driver makes on a busy road. 

### 03 JH Break

1. Its artificial neural networks 'learn' the correlations between the visual perception of the environment and the mechanical control of the vehicle (steering, accelerating, braking) together with ethical decisions to be taken in a few milliseconds in case of danger. 
1. Driving requires high cognitive skills that cannot be left to improvisation, but also rapid problem-solving that is possible only thanks to habit and training that are not completely conscious. 
1. Driving remains essentially a social and cooperative activity, which follows both codified rules (with legal constraints) and spontaneous ones, including a tacit cultural code which is different in each locality. 
1. It is deemed difficult to encode such a complex activity, and even the entrepreneur Elon Musk has admitted, after not a few fatal accidents of Tesla cars, that 'generalized self-driving is a hard problem'. 
1. In all its problematic aspects, however, the industrial project of self-driving vehicles has made clear that the task of driving is not merely 'mechanical'. 
1. If the skill of driving can be translated into an algorithmic model to begin with, it is because driving is a logical activity -- because, ultimately, *all labour is logic*.  

### 04 JH Break

1. What, then, is the relationship between labour, rules, and automation, i.e., the invention of new technologies? 
1. This entanglement is the core problem of AI which this book seeks to explore. 
1. But this is not a completely new perspective for framing AI. 
1. The historian of science Lorraine Daston, for example, has already illustrated this problem in the great calculation projects of the Enlightenment that preceded automatic computation. 
1. In the late eighteenth century, in order to produce the lengthy logarithmic tables necessary for the modernisation of revolutionary France, the mathematician **Gaspard de Prony** had the idea to apply the industrial method of the division of labour (canonised by Adam Smith in *The Wealth of Nations*) to hand calculation. 
1. For this purpose, de Prony arranged a *social algorithm* -- a hierarchical organisation of three groups of clerks which divided the toil and each performed one part of the long calculation, eventually composing the final results. 

### 05 JH Break

1. A few years later, in industrial England, Charles Babbage adopted the intuition of the division of labour as the internal principle of the Difference Engine, designing in this way the first prototype of the modern computer. 
1. Babbage, importantly, understood that the division of labour was not only a principle to design machines but also to compute the costs of production (what has been known since then as the 'Babbage principle').  
1. In the industrial age, the supervision of the division of labour used to be the task of the factory's master. 
1. The eye of the master, in workshops and also in camps and plantations, had long supervised and disciplined workers, drawing the plans of assembly lines as well as the shifts of forced labour. 
1. Before industrial machines were invented, urban sweatshops and colonial estates were already 'mechanical' in their regime of body discipline and visuality. 
1. As the philosopher Michel Foucault illustrated, the imposition of such disciplinary techniques -- based on the segmentation of time, space, and relations -- prepared the terrain for the capitalist regime of labour exploitation. 

### 06 JH Break

1. In parallel, the rationalist view of the world helped to further describe the movement of the human body in detail and draft its mechanisation. 
1. Historian Sigfried Giedion detailed this process in his famous volume *Mechanisation Takes Command*. According to Giedion, mechanisation begins 'with the concept of Movement', then it replaces handicraft, and, finally, its full development is 'the assembly line, wherein the entire factory is consolidated into a synchronous organism'.
1. This mechanical mentality culminated in Taylorism -- a system of 'scientific management' that sought to economize workers' movements down to the finest detail. 
1. Indeed, as the political economist Harry Braverman once noted, 'Taylor understood the Babbage principle better than anyone of his time, and it was always uppermost in his calculations.' 
1. In order to surveil the worker's smallest gesture, the Taylorist system even acquired cinematographic eyes: the factory's master became a sort of movie director who filmed workers in order to measure and optimize their productivity, somehow realising what media scholar Jon Beller has termed the 'cinematic mode of production'. 
1. Taylorism prompted the discipline of 'time and motion study' which was pursued, in the same years, by both the Soviet revolutionary Aleksei Gastev and the US engineers Frank and Lillian Gilbreth, who introduced similar photographic techniques such as, respectively, the *cyclogram*, and *chronocyclegraph*. 

### 07 JH Break

1. This book follows these analytical studies of the labour process through the industrial age up to the rise of AI, aiming to show how the 'intelligence' of technological innovation has often originated from the imitation of these abstract diagrams of human praxis and collective behaviours.  
1. When industrial machines such as looms and lathes were invented, in fact, it was not thanks to the solitary genius of an engineer but through the imitation of the collective diagram of labour: by capturing the patterns of hand movements and tools, the subdued creativity of workers' know-how, and turning them into mechanical artefacts. 
1. Following this theory of invention, which was already shared by Smith, Babbage, and Marx in the nineteenth century, this book argues that the most sophisticated 'intelligent' machines have also emerged by imitating the outline of the collective division of labour. 
1. In the course of this book, this theory of technological development is renamed the *labour theory of automation*, or *labour theory of the machine*, which I then extend to the study of contemporary AI and generalise into a *labour theory of machine intelligence*. 
1. Already for Marx, the master was no longer an individual but, as mentioned in the opening quote to this introduction, an integrated power made up of 'the science, the gigantic natural forces, and the mass of the social labour embodied in the system of machinery'. 

### 08 JH Break

1. After the expansion of 'the division of labour in society', as Ã‰mile Durkheim recorded at the end of the nineteenth century, the eye of the master evolved as well into new technologies of control such as statistics and the global 'operations of capital' (to use Sandro Mezzadra and Brett Neilson's apt phrase). 
1. Since the end of the twentieth century, then, the management of labour has turned all of society into a 'digital factory' and has taken the form of the software of search engines, online maps, messaging apps, social networks, gig- economy platforms, mobility services, and ultimately AI algorithms, which have been increasingly used to automate all the abovementioned services. 
1. It is not difficult to see AI nowadays as a further centralisation of digital society and the orchestration of the division of labour throughout society. 
1. The thesis that the design of computation and 'intelligent machines' follow the schema of the division of labour is not heretical but receives confirmation from the founding theories of computer science, which have inherited a subtext of colonial fantasy and class division from the industrial age. 

### 09 JH Break

1. The celebrated genius of automated computation Alan Turing, for instance, himself reiterated a hierarchical and authoritarian mode of thinking. In a 1947 lecture, Turing envisioned the Automatic Computing Engine (ACE), one of the first digital computers, as a centralised apparatus that orchestrated its operations as a hierarchy of master and servant roles:
	* *Roughly speaking those who work in connection with the ACE will be divided into its masters and its servants.* 
	* *Its masters will plan out instruction tables for it, thinking up deeper and deeper ways of using it.* 
	* *Its servants will feed it with cards as it calls for them. They will put right any parts that go wrong.* 
	* *They will assemble data that it requires. In fact the servants will take the place of limbs.* 
	* *As time goes on the calculator itself will take over the functions both of masters and of servants. The servants will be replaced by mechanical and electrical limbs and sense organs.*
	* *One might for instance provide curve followers to enable data to be taken direct from curves instead of having girls read off values and punch them on cards. The masters are liable to get replaced because as soon as any technique becomes at all stereotyped it becomes possible to devise a system of instruction tables which will enable the electronic computer to do it for itself.*
	* *It may happen however that the masters will refuse to do this. They may be unwilling to let their jobs be stolen from them in this way.* 
	* *In that case they would surround the whole of their work with mystery and make excuses, couched in well chosen gibberish, whenever any dangerous suggestions were made. I think that a reaction of this kind is a very real danger.*
1. The prose of the young Turing, in dividing computing tasks between 'masters', 'servants', and 'girls' is fierce. 

### 10 JH Break

1. It is reminiscent of Andrew Ure's gothic depictions of the industrial factory in the Victorian age as 'a vast automaton, composed of various mechanical and intellectual organs, acting in uninterrupted concern for the production of a common object, all of them being subordinated to a self-regulated moving force'. 
1. Similarly, Turing imagined an intelligent automaton that in the future would be able to reprogram itself and replace both masters and servants. 
1. Turing's vision is contradicted today by the army of 'ghost workers' from the Global South, who, as Mary Gray and Siddharth Suri have documented, are removed from sight to let the show of machine autonomy go on. 
1. Paradoxically for Turing, AI came to replace mostly masters, that is managers, rather than servants -- workers are needed (and always will be) to produce data and value for the voracious pipelines of AI and its global monopolies, and, on the other hand, to provide the maintenance of such a mega-machine under the form of content filtering, security checks, evaluation and non-stop optimisation. 
1. As gender studies scholars Neda Atanasoski and Kalindi Vora have pointed out, the dreams of full automation and AI such as Turing's are not neutral but are historically grounded on the 'surrogate humanity' of enslaved servants, proletarians, and women that have made possible, through their invisible labour, the universalistic ideal of the free and autonomous (white) subject.

### 11 The many histories of AI

1. Writing a history of AI in the current predicament means reckoning with a vast ideological construct: among the ranks of Silicon Valley companies and also hi-tech universities, propaganda about the almighty power of AI is the norm and sometimes even repeats the folklore of machines achieving 'superhuman intelligence' and 'self-awareness'. 
1. This folklore is well exemplified by apocalyptic *Terminator* narratives, in which AI systems would achieve technological singularity and pose an 'existential risk' to the survival of the human species on this planet, as the futurologist Nick Bostrom, among others, professes. 
1. Mythologies of technological autonomy and machine intelligence are nothing new: since the industrial age, they have existed to mystify the role of workers and subaltern classes. 
1. As Schaffer has remarked, while describing the cult of automata in Babbage's age, 'To make machines look intelligent it was necessary that the sources of their power, the labour force which surrounded and ran them, be rendered invisible.' 
1. Speculative narratives aside, which never go into sufficient technical detail to clarify which kind of algorithms would actually execute 'superintelligence', one also finds today numerous *technical histories* of AI that, on the other hand, promise to explain its complex algorithms. 

### 12 JH Break

1. These technical overviews often voice corporate expectations for a 'master algorithm' that would solve all tasks of perception and cognition at a prodigious rate of information compression (because this is the very unromantic metrics by which 'intelligent' systems are ultimately assessed). 
1. Once again, these readings rarely consider the historical contexts and social implications of automation, and draw a linear history of mathematical achievements which reinforces technological determinism. 
1. Within these technical histories of AI, one should also include cognitive science, as a considerable part of this field actually developed under the influence of computer science. 
1. Margaret Boden's monumental two-volume *Mind as Machine* (2006) remains probably one of the most detailed histories of AI as cognitive science, showing the complexity of this genealogy, however, without ideological fervour.
1. Resisting such narrow technical perspectives, a growing number of authors have started addressing the social implications of AI from the standpoint of workers, communities, minorities, and society as a whole. 
1. These authors question the virtuosity of algorithms that claim to be 'intelligent' while in fact amplifying inequalities, perpetuating gender and racial biases, and consolidating new form of knowledge extractivism. 

### 13 JH Break

1. Thanks to books such as Cathy O'Neil's *Weapons of Math Destruction* (2016), Safiya Noble's *Algorithms of Oppression* (2018), Ruha Benjamin's *Race after Technology* (2019), and Wendy Chun's *Discriminating Data* (2021), among many others, the new field of critical AI studies is growing. This novel scholarship builds upon older investigations of AI, cybernetics, and Cold War rationality from previous decades, among which should be included Alison Adam's *Artificial Knowing* (1998), Philip Agre's *Computation and Human Experience* (1997), Paul Edwards's *The Closed World* (1996), Joseph Weizenbaum's *Computer Power and Human Reason* (1976), and Hubert Dreyfus's paper for the Rand Corporation 'Alchemy and Artificial Intelligence' (1965), which is usually considered the first philosophical critique of AI.
Within the expanding landscape of critical works, this book's concern is to illuminate the social genealogy of AI and, importantly, the standpoint -- the social classes -- from which AI has been pursued as a vision of the world and epistemology. 
1. Different social groups and configurations of power have shaped information technologies and AI in the past century. 

### 14 JH Break

1. Rather than on the 'shoulders of giants', as the saying goes, it could be said that the early paradigms of mechanical thinking and late machine intelligence have been developed, in different times and ways, 'on the shoulders' of merchants, soldiers, commanders, bureaucrats, spies, industrialists, managers, and workers. In all these genealogies, the automation of labour has been the key factor, but this aspect is often neglected by a historiography of technology that privileges science's point of view 'from above'.
1. A common approach, for instance, links quite deterministically the rise of cybernetics, digital computation, and AI to abundant funding from the US military during World War II and in the Cold War period. 
1. Yet recent studies have clarified that the archipelago of such 'war rationality' was quite unstable and cultivated paradigms such as game theory and linear programming that were also key in modelling the arms race and military logistics. 
1. The influence of state apparatuses on information technologies, anyhow, started well before the military acceleration of World War II: the automation of information retrieval and statistical analysis dates back to the need to mechanise public bureaucracy and government work, at least since the 1890 United States census that introduced the Hollerith machine to process punched cards. 

### 15 JH Break

1. The 'government machine' (as Jon Agar has called it) anticipated the rise of the large data centres of the digital age, which have been, as is notorious, not just the business of internet companies but also of intelligence agencies, as the mathematician Chris Wiggins and historian Matthew L. Jones have detailed. In short, for more than a hundred years, it has always been the accumulation of 'big data' about society and its behaviours that prompted the development of information technologies, from Hollerith's tabulator to machine learning itself.
1. In summary, AI represents the continuation of data analytics techniques first supported by state bureaus, secretly cultivated by intelligence agencies, and ultimately consolidated by internet companies into a planetary business of surveillance and forecasting. 
1. This reading, however, is once again a history 'from above' that focuses on only the techniques of control and rarely the subjects on whom this control is exercised. 
1. The targets of this power (or 'surveillance capitalism' in Shoshana Zuboff's definition) are usually described not as actors possessing autonomy and 'intelligence' on their own but as passive subjects of measurement and control. 
1. This is a problem of critical theory in general and critical AI studies in particular: although these studies are concerned about the impact of AI on society, they often overlook the role of collective knowledge and labour as the primary source of the very 'intelligence' that AI comes to extract, encode, and commodify. 

### 16 JH Break

1. Moreover, these studies often fail to see the contribution of social forms and forces to the key stages of technological invention and development. 
1. A true critical intervention should challenge this hegemonic position of AI as the unique 'master' of collective intelligence. 
1. The Italian philosopher Antonio Gramsci once argued against the hierarchies of education that 'all human beings are intellectuals': in a similar way, this book aims at rediscovering the centrality of the social intelligence that informs and empowers AI. 
1. It also contends -- in a more radical thesis -- that such social intelligence shapes the very design of AI algorithms from within.  
1. This book is intended as an incursion into both the technical and social histories of AI, integrating these approaches into a sociotechnical history that may identify also the economic and political factors that influenced its inner logic. 
1. Rather than siding with a conventional social constructivism and going beyond the pioneering insights of social informatics, it tries to extend to the field of AI the method of historical epistemology -- one propagated in the history of science, in a different way, by Boris Hessen, Henryk Grossmann, Georges Canguilhem, and Gaston Bachelard, and more recently by the work of the Max Planck Institute for the History of Science in Berlin, among other initiatives. 
1. Where social constructivism generically emphasises the influence of external factors on science and technology, historical epistemology is concerned with the dialectical unfolding of social praxis, instruments of labour, and scientific abstractions within a global economic dynamics. 

### 17 JH Break

1. This book attempts to study AI and algorithmic thinking in a similar way that historical and political epistemology has studied, in the modern age, the rise of mechanical thinking and scientific abstractions in relation to socio-economic developments. 
1. In this respect, over the past decades, a political epistemology of science and technology has also been strongly pursued by feminist theorists such as Hilary Rose, Sandra Harding, Evelyn Fox Keller, and Silvia Federici, among others. 
1. These authors have convincingly explained the rise of modern rationality and mechanical thinking (to which AI also belongs) in relation to the transformation of women's body, and the collective body in general, into a productive and docile machine. 
1. In the traditions of political epistemology, we should also consider the labour process analysis that was initiated by Braverman's Labor and Monopoly Capital (1974) and the workers' inquiries of Italian operaismo, which Romano Alquati, for instance, conducted at the Olivetti computer factory in Ivrea as early as 1960. 
1. Braverman and Alquati pioneered influential works that first showed how Babbage's automated computation projects in the nineteenth century as much as cybernetics in the twentieth were inherently related to the sphere of labour and its organisation.  

### 18 JH Break

1. The automation of cognition as pattern recognition The translation of a labour process into a logical procedure and subsequently into a technical artefact is rarely straightforward and flawless; it often displays instead a spurious and experimental character. 
1. In this sense, the title The Eye of the Master contains not only a political but also a technical analogy. 
1. It signals, somewhat ironically, the ambivalence of the current paradigm of AI -- deep learning -- which emerged not from theories of cognition, as some may believe, but from contested experiments to automate the labour of perception, or pattern recognition. 
1. Deep learning has evolved from the extension of 1950s techniques of visual pattern recognition to non-visual data, which now include text, audio, video, and behavioural data of the most diverse origins. 

### 19 JH Break

1. The rise of deep learning dates to 2012, when the convolutional neural network AlexNet won the ImageNet computer vision competition. 
1. Since then, the term 'AI' has come to define by convention the paradigm of artificial neural networks which, in the 1950s, it must be noted, was actually its rival (an example of the controversies that characterise the 'rationality' of AI). 
1. Stuart and Hubert Dreyfus illuminated this schism in their 1988 essay 'Making a Mind versus Modeling the Brain', in which they outlined the two lineages of AI -- symbolic and connectionist -- that, based on different logical postulates, have also followed different destinies. 
1. Symbolic AI is the lineage that is associated with the 1956 Dartmouth workshop for which John McCarthy coined the questionable term 'artificial intelligence'. 
1. Its key applications have been the Logic Theorist and General Problem Solver -- and the array of expert systems and inference engines in general -- which were proven trivial and prone to combinatorial explosion. 
1. Connectionism, on the other hand, is the lineage of artificial neural networks pioneered by Frank Rosenblatt's invention of the 'perceptron' in 1957, which unfolded into convolutional neural networks in the late 1980s and, eventually, launched the deep learning architecture that has prevailed since the 2010s.

### 20 JH Break

1. The two lineages pursue different kinds of logic and epistemology. 
1. The former professes that intelligence is a representation of the world (knowing- that) which can be formalised into propositions and, therefore, mechanised following deductive logic. 
1. The latter, in contrast, argues that intelligence is experience of the world (knowing-how) which can be implemented into approximate models constructed according to inductive logic. 
1. Pace corporate propaganda and computationalist philosophies of the mind, neither of these two paradigms has managed to fully imitate human intelligence. 
1. Machine learning and deep artificial neural networks, however, due to their resolution in rendering multidimensional data, have proven quite successful in techniques of pattern recognition and, therefore, in the automation of numerous tasks. 
1. Against a tradition which repeats the overly celebrated saga of the Dartmouth workshop, this book highlights the origins of artificial neural networks, connectionism, and machine learning as a more compelling history of AI about which, especially regarding Rosenblatt's work, critical and exhaustive literature is still missing.

### 21 Structure of the book

1. The book is divided into three sections: a methodological and introductory first chapter and two main historical parts on the industrial and information ages respectively. 
1. This book does not pursue, however, a linear history of technology and automation. 
1. Rather, each chapter can be read as an independent 'workshop' for the study of algorithmic practices and machine intelligence.  
1. Chapter 1 moves from the need to clarify, before anything else, the central notion of computation: the algorithm.
1. What is an algorithm? In computer science, it can be defined as a finite procedure of step-by-step instructions to turn an input into an output making the best use of the given resources. 
1. The chapter challenges this purely technical definition of the algorithm and argues for a materialist critique that may recognise its economic and social roots. 

### 22 JH Break

1. After all, as with other abstract notions, such as number or mechanism, the algorithm has a long history; the mathematician Jean-Luc Chabert finds that 'algorithms have existed since the beginning of time and existed long before a special word was coined to describe them'. 
1. By excavating the social mathematics of the ancient Hindu ritual Agnicayana, the chapter argues that algorithmic thinking and practices have belonged to all civilisations, not only to the metalanguage of Western computer science.
1. Against mathematical and philosophical intuitionism, which believes in the full independence of mental constructs, the chapter stresses that algorithmic thinking emerged as a *material abstraction*, through the interaction of mind with tools, in order to change the world and solve mostly economic and social problems. 
1. Deliberately trenchant, the main thesis of this chapter is that *labour is the first algorithm*.  
1. The two main parts of the book endeavour to study machine intelligence in two historical epochs, signalling the parallel development of similar problematics. 

### 23 JH Break

1. Part I is concerned with labour as a source of knowledge and with the *automation of mental labour* during the industrial age in the UK. 
1. This historical moment is usually studied from the perspective of manual labour, capital accumulation, and fossil energy, and rarely in its cognitive components. 
1. Part II, on the other hand, analyses the rise of connectionism (the doctrine of artificial neural networks) in the circles of US cybernetics between the 1940s and 1960s. 
1. Artificial neural networks emerged from the project of the *automation of visual labour* (commonly termed as pattern recognition), which is something distinct from manual and mental labour. 
1. The study of the role of knowledge, mental labour, and science in the nineteenth century is necessary, I contend, to understand the history of automation that prepared the rise of AI in the twentieth century. 

### 24 JH Break

1. Under different rubrics, the two parts of the book deal with the same problem: the relation between the forms of technological innovation and social organisation.  
1. As already expounded by historians of science such as Daston and Schaffer, it is easier to find the impetus for modern computation in the workshops of the industrial age than in the volumes of mathematics or natural philosophy of the time. 
1. Chapter 2, in this sense, revisits Babbage's pioneering experiments in automated computation -- the Difference and the Analytical Engines -- focusing on their economic matrix and avoiding the usual machine hagiography. 
1. In order to understand the design of these early computers (and their variant of 'machine intelligence'), the chapter explicates two of Babbage's principles of labour analysis. 
1. His first analytical principle, the *labour theory of the machine*, states that the design of a machine imitates and replaces the diagram of a previous division of labour. 
1. The second, the *principle of labour calculation* (usually called the 'Babbage principle') states that the division of labour into small tasks makes it possible to measure and purchase the exact quantity of labour that is necessary for production. 
1. These two principles, combined together, describe the industrial machine not only as a means for augmenting labour but also as an *instrument* (and implicit *metrics*) for measuring it. 

### 25 JH Break

1. Babbage applied both principles to the automation of hand calculation: computation emerged, then, not only as the automation of mental labour but also as a metrics for the calculus of its cost.  
1. Beyond the usual 'thermodynamic' interpretations of manual labour, chapter 3 points out that sophisticated notions of mental labour, collective intelligence, and knowledge alienation were already elaborated in the industrial era.
1. It examines the circulation of ideas between the making of nineteenth-century political economy and the Mechanics' Institute movement, between the March of Intellect campaign and the Machinery Question (a debate that animated English society about technological unemployment). 
1. The chapter expands, from opposite angles, the previous reflections on Babbage's principles of labour analysis and invention. 
1. On the one hand, it shows that, well before the theoreticians of the knowledge society of the twentieth century, a *knowledge theory of labour* was already advanced by Ricardian socialists such as William Thompson and Thomas Hodgskin. 
1. On the other hand, it urges a recognition of the influence of industrial machines and instruments on the development of the knowledge of nature, expanding on a *machine theory of science*. 
1. The expression 'machine intelligence' ultimately acquires at least four meanings in this discussion: the human knowledge of the machine, the knowledge embodied by the machine's design, the human tasks automated by the machine, and the new knowledge of the world made possible by its use.  

### 26 JH Break

1. Chapter 4 centres on the relation between Babbage and another pillar of the political economy of the industrial age, Karl Marx -- a relation which remains under-investigated. 
1. The chapter, like every other in this book, explores the imbrication of knowledge into material acts and artefacts, also reading Marx's theories under this lens. 
1. In a famous fragment from the *Grundrisse*, Marx predicted that the progressive accumulation of knowledge (or what he called the 'general intellect') into machines would undermine the laws of capitalist accumulation and cause its ultimate crisis. 
1. Especially thanks to the interpretation of Italian *operaismo* after 1989, this unorthodox passage (renamed as 'The Fragment on Machines') has had a vast reception among generations of scholars and activists as prophesising the knowledge economy, the dotcom crash, or the rise of AI. 
1. The chapter uncovers, after decades of speculation, the origin of the idea of the 'general intellect' -- which Marx first encountered in William Thompson's book *An Inquiry into the Principles of the Distribution of Wealth* (1824).  1. The chapter explains, more importantly, why this notion then disappeared in Marx's *Capital*. 
1. In Thompson, Marx found the idea of the virtuous accumulation of knowledge but also the argument that once knowledge has been alienated by machines, it becomes hostile to workers. 

### 27 JH Break

1. But it was in Babbage that Marx found an alternative theory to resolve the ambiguous role that knowledge and science had in the industrial economy. 
1. In *Capital*, Marx replaced the utopian expectations around the 'general intellect' with the material figure of the 'general worker' (*Gesamtarbeiter*), which was another name for the extended cooperation of labour. 
1. The figure of the general worker, as a sort of super-organism connecting humans and machines, marks in this book the passage to the age of cybernetics and its experiments in self-organisation. 
1. As a transition to the second part, chapter 5 briefly summarises the transformation of labour from the industrial to the cybernetic age, clarifying its bifurcation into *abstract energy* and *abstract form* (or *information*).  
1. Part II focuses on connectionism as the main genealogy of current AI systems (avoiding reiterating known literature on cybernetics, information theory, and symbolic AI). 

### 28 JH Break

1. Chapter 6 frames the rise of artificial neural networks from a neglected perspective -- that is, from the studies on the self-organisation of organisms and machines (which have passed unnoticed even to Boden in her extensive history of AI). 
1. Theories of self-organisation are today popular in physics, chemistry, biology, neuroscience, and ecology, but it took cybernetics, rather than a natural science, to trigger the debate on self-organisation in the mid-twentieth century. 
1. The chapter illustrates the paradigms of self-organising computation that have contributed, among others, to the consolidation of connectionism -- in particular, Warren McCulloch and Walter Pitts's original idea of neural networks (1943--47), John von Neumann's cellular automata (1948), and Rosenblatt's 'perceptron' (1957). 
1. The chapter investigates how cybernetic theories of self-organisation also responded to sociotechnical changes. 
1. As happened in previous centuries with other variants of mechanistic thinking, cybernetics projected onto brains and nature forms of organisation that were already part of the technical composition of the surrounding society. 

### 29 JH Break

1. A key example is the telegraph network, which was used, in the nineteenth century, as an analogy for the nervous system and, in the twentieth century, to formalise neural networks -- not to mention the Turing machine itself.  
1. Chapter 7 retraces McCulloch and Pitts's idea of artificial neural networks to the forgotten Gestalt controversy: the debate on whether or not human perception is an act of cognition that can be analytically represented and therefore mechanised. 
1. Textbooks on machine learning usually repeat that McCulloch and Pitts were inspired by the neurophysiology of the brain, while overlooking this intellectual confrontation. 
1. It was in the aftermath of these debates, in fact, that the expression 'Gestalt perception' gradually morphed, in military and academic publications, into the well-known expression 'pattern recognition'. 
1. The Gestalt controversy is a cognitive fossil of unresolved problems whose study can help to understand the form and limits that deep learning has inherited -- specifically, the unresolved opposition between perception and cognition, image, and logic, that haunted the technoscience of the twentieth century

### 30 JH Break

1. Chapter 8 clarifies the ambivalent role that the neoliberal economist Friedrich Hayek had in consolidating connectionism. 
1. In his 1952 book *The Sensory Order*, Hayek proposed a connectionist theory of the mind which was already far more advanced than the definitions of AI that emerged from the 1956 Dartmouth workshop. 
1. In this text, as McCulloch and Pitts had also proposed, Hayek speculated about the possibility of a machine fulfilling a similar function to 'the nervous system as an instrument of classification'. 
1. Hayek studied the self-organisation of the mind in a similar fashion to the cyberneticians but in order to serve a different agenda: not industrial automation but the autonomy of the market.  

### 31 JH Break

1. Chapter 9 focuses on one of the most important and least studied episodes in the history of AI: Rosenblatt's invention of the 'perceptron' artificial neural network in the 1950s. 
1. In spite of its limitations, the perceptron constituted a breakthrough in the history of computation because it automated, for the first time, a technique of statistical analysis; it is remembered, for this reason, as the first algorithm of machine learning. 
1. As a technical form, the perceptron claimed to imitate biological neural networks. 
1. But as a mathematical form, it expressed a different trick: in order to solve pattern recognition, it represented the pixels of an image as independent coordinates in a multidimensional space. 
1. Interestingly, the statistical method of multidimensional projection originated from the fields of psychometrics and eugenics in the late nineteenth century, and was analogous to the technique employed by Charles Spearman for evaluating 'general intelligence' in the controversial practice of the intelligence quotient (IQ) test. 

### 32 JH Break

1. This is a further proof of the social genealogy of AI: the first artificial neural network -- the perceptron -- was born not as the automation of *logical reasoning* but of a statistical method originally used to *measure intelligence* in cognitive tasks and to organise social hierarchies accordingly.  
1. The conclusion considers how the operative principle of AI, in fact, is not just labour automation but also the imposition of social hierarchies of manual and mental labour *through* automation. 
1. From the nineteenth century to the twentieth, the 'eye of the master' of industrial capitalism extended to the whole society and imposed new forms of control, also based on statistical measurements of 'intelligence', to discriminate workers into classes of skill. 
1. This was, for instance, one of the direct applications of the IQ test according to the US psychologist Lewis Terman, who argued in 1919 that 'the IQ of 75 or below belongs ordinarily in the unskilled labor class, that 75 to 85 is preeminently the range for semiskilled labor, and that 80 or 85 is ample for success in some kinds of skilled labor'. 

### 33 JH Break

1. AI continues this process of encoding social hierarchies and discriminating among the labour force by imposing indirectly a metrics of intelligence. 
1. The class, gender, and racial bias that AI systems notoriously amplify should not only be considered a technical flaw, but an intrinsic discriminatory feature of automation in a capitalist context. 
1. The impact of AI bias is not limited to social oppression: it also leads to an implicit imposition of labour and knowledge hierarchies that reinforces the polarisation of skilled and unskilled workers in the job market. 
1. The replacement of traditional jobs by AI systems should be studied together with the displacement and multiplication of precarious, underpaid, and marginalised jobs across a global economy. 
1. AI and ghost work appear to be, in this view, the two sides of the one and same mechanism of labour automation and social psychometrics.  

### 34 JH Break

1. This book proposes the labour theory of automation, in the end, not only as an analytical principle to dismantle the 'master algorithm' of AI monopolies but also as a synthetic principle: as a *practice of social autonomy* for new forms of knowledge making and new cultures of invention.
